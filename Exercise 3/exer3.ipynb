{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Χρησιμοποιήθηκαν 2 free pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import dask.dataframe as dd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Διαβάζουμε το αρχείο με τις τριάδες και φιλτράρουμε ανά iterate την συνθήκη που υπάρχει, πάνω από 30 reviews ανα χρήστη και άνω από 50 review ανά επιχείρηση. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272933\n",
      "167056\n",
      "#####################################\n",
      "132040\n",
      "117066\n",
      "#####################################\n",
      "109447\n",
      "106727\n",
      "#####################################\n",
      "104789\n",
      "103946\n",
      "#####################################\n",
      "103320\n",
      "103070\n",
      "#####################################\n",
      "102951\n",
      "102852\n",
      "#####################################\n",
      "102672\n",
      "102472\n",
      "#####################################\n",
      "102292\n",
      "102093\n",
      "#####################################\n",
      "101973\n",
      "101923\n",
      "#####################################\n",
      "101923\n",
      "101923\n",
      "#####################################\n",
      "101923\n",
      "101923\n",
      "#####################################\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('philly_users_businesses_stars.csv')\n",
    "for i in range(11):\n",
    "    df.columns\n",
    "    # another way \n",
    "    df = df[df.user_id.isin(df.user_id.value_counts().loc[lambda x: x > 30].index)]\n",
    "    #df = df[df.groupby('user_id')['user_id'].transform('size').gt(15)]\n",
    "    print(len(df.index))\n",
    "    # another way \n",
    "    df = df[df.business_id.isin(df.business_id.value_counts().loc[lambda x: x > 50].index)]\n",
    "    #df = df[df['business_id'].map(df['business_id'].value_counts()).gt(15)]\n",
    "    print(len(df.index))\n",
    "    df = df.dropna()\n",
    "    print(\"#####################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Εδώ διαβάζουμε το αρχείο με τους φίλους κάθε χρήστη. Λόγω του μεγάλου μεγέθους του αρχείου χρησιμοποιούμε το dask για να κάνουμε batches των 1000000 χρηστών και όσες γραμμές έχουν στην στήλη user_id έναν χρήστη που ανήκει στο friends_series αποθηκεύεται.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame using dask\n",
    "users = dd.read_json('yelp_academic_dataset_user.json', blocksize=1e6)\n",
    "friends_series = pd.Series(df['user_id'].values)\n",
    "\n",
    "# Define a function to filter the DataFrame based on the values in x\n",
    "def filter_data(df):\n",
    "    return df[df['user_id'].isin(friends_series)]\n",
    "\n",
    "# Apply the filter_data function to each chunk of the DataFrame in parallel\n",
    "result = users.map_partitions(filter_data).compute()\n",
    "\n",
    "result.to_csv('user_friends_unfiltered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Τώρα έχουμε ένα DataFrame με δύο στήλες, μια στήλη τα user_id και μια άλλη που έχει σε μορφή λίστας τους φίλους του χρήστη. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                     user_id                                            friends\n",
       "11   IpLRJY4CP3fXtlEd8Y4GFQ  [hdwDo7CLh9aN_9PckAos4Q, ci-mepWGgsgGT3sFI2mhM...\n",
       "17   RgDVC3ZUBqpEe6Y1kPhIpw  [sHozd2pcOKwHtPr8VlZJfg, 7mL9cvICl8fuCQTM89a-S...\n",
       "25   KrIL3TIOJI-tjvU6BlcA-g  [eUlLKiRbX3k4VS3Ko_WxTA, nmiOEav_m5eT08zz8BIi4...\n",
       "1    ouODopBKF3AqfCkuQEnrDg  [tlEHfYMPIm8-AMMk3T1s0w, aOkQtJvCvGzLUNVtaGb9x...\n",
       "47   Z2pXm4f-2O5ZpMUmXuYK0Q  [c4eh4aq5Bw9zVMt4xLG2ew, nBdv5Br4G8pDWXXqSXhUu...\n",
       "..                      ...                                                ...\n",
       "885  iUo7JE5Uj_LsNH0BxXh_kQ  [ZuRBTpKHifS0aXplqJLvGg, hv-GtL9hsBqz8oM4vteGi...\n",
       "884  DrvmH6hJifrAyqQR0Sliww  [YljmfktfbakMINbP1G-gKg, gWZETLPu_ihAtLOYtrm0m...\n",
       "267  TdW4MVRT2MGdFPD6DoZSbQ  [gWZETLPu_ihAtLOYtrm0mw, 6BkR1OS11VsARi1typB3_...\n",
       "893  v9FT1O5vdOHlzOYpyc-Y2w                                             [None]\n",
       "8    U165gjpO81auHqPTZbf3TQ  [hukAFNR0SeHLnHCBLI-TSQ, gok-GLiwpkjJvpOfaqnKR...\n",
       "\n",
       "[1604 rows x 2 columns]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_of_users = result[['user_id', 'friends']].copy()\n",
    "friends_of_users['friends'] = friends_of_users['friends'].apply(lambda x: x.split(', '))\n",
    "friends_of_users.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Εδώ δημιουργούμε το γράφημα. Χρησιμοποιώντας την iterrows πηγαίνουμε από γραμμή σε γραμμή, κρατάμε τον χρήστη και δημιουργούμε ακμές με όλους τους φίλους του, μονάχα βέβαια άμα δεν έχουν μπει ήδη. Τo networkx δημιουργεί αυτόματα έναν νέο κόμβο με κάθε νέα ακμή. Στο τέλος κρατάμε την μεγαλύτερη συνεκτική συνιστώσα και βλέπουμε ότι πράγματι έχουμε 1504 χρήστες-κόμβους και 887 επιχειρήσεις.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of nodes: 1504\n",
      "Amount of edges: 19347\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "user_nodes = friends_of_users['user_id'].values \n",
    "G.add_nodes_from(user_nodes) \n",
    "\n",
    "for i, row in friends_of_users.iterrows():\n",
    "    node = row['user_id'] # Get the node from the first column of the row\n",
    "    friends = row[1] # Get the list of friends from the second column of the row\n",
    "    for friend in friends:\n",
    "        if(friend in user_nodes): # Check if the friend is already a node in the graph\n",
    "            G.add_edge(node, friend) # Add an edge to the graph between the node and the friend\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "CC_max = nx.subgraph(G,largest_cc)\n",
    "print(\"Amount of nodes:\",len(CC_max.nodes()))\n",
    "print(\"Amount of edges:\",len(CC_max.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       user_id             business_id  stars\n",
      "3       smOvOajNG0lS4Pq7d8g4JQ  RZtGWDLCAtuipwaZ-UfjmQ    4.0\n",
      "5       IQsF3Rc6IgCzjVV9DE8KXg  eFvzHawVJofxSnD7TgbZtg    5.0\n",
      "10      ZGjgfSvjQK886kiTzLwfLQ  EtKSTHV5Qx_Q7Aur9o4kQQ    5.0\n",
      "11      IKbjLnfBQtEyVzEu8CuOLg  VJEzpfLs_Jnzgqh5A_FVTg    4.0\n",
      "13      NUtIAX-ygn474tDg5nmesg  6LCZLGa09Qifn6rG7-DNrg    4.0\n",
      "...                        ...                     ...    ...\n",
      "113676  k6F3Ig1Sj1IqPfTgKhOkzw  cGX-1IUwXOjkUqZbkKYcjw    4.0\n",
      "126492  RCZ5M9o2-fxgFuurpmEs3w  cGX-1IUwXOjkUqZbkKYcjw    4.0\n",
      "130758  WIDiCSoG68ScNeLLhORN6A  w55VlTgAoRXPnqFte3j9ew    5.0\n",
      "164063  g8Wrs02Za0rkbFTH7rt3lw  Ldch7Nc5gaZrhcIRd7mcjw    4.0\n",
      "169949  nUD_Duu-NR7qfyq8fgqiAQ  KyDcAU41QDQpYAFyK6Q6hg    5.0\n",
      "\n",
      "[1504 rows x 3 columns]\n",
      "                       user_id             business_id  stars\n",
      "3       smOvOajNG0lS4Pq7d8g4JQ  RZtGWDLCAtuipwaZ-UfjmQ    4.0\n",
      "5       IQsF3Rc6IgCzjVV9DE8KXg  eFvzHawVJofxSnD7TgbZtg    5.0\n",
      "10      ZGjgfSvjQK886kiTzLwfLQ  EtKSTHV5Qx_Q7Aur9o4kQQ    5.0\n",
      "11      IKbjLnfBQtEyVzEu8CuOLg  VJEzpfLs_Jnzgqh5A_FVTg    4.0\n",
      "13      NUtIAX-ygn474tDg5nmesg  6LCZLGa09Qifn6rG7-DNrg    4.0\n",
      "...                        ...                     ...    ...\n",
      "868448  Jt3GylPuH64uA3zTdbMdCg  w9_EQB0SuAFYxPMcfY_P_g    5.0\n",
      "871002  NUtIAX-ygn474tDg5nmesg  KscVqYYG7ziAroZhfNb0Ng    5.0\n",
      "871790  5kcLlhJPLJL_GLwrAdbZAA  gkrDiCU_sRZKwuBlhEzv6A    2.0\n",
      "876415  IH0ToaZ8hJXO2pVieN7dpQ  8XjxHeV66F4eoIy06rW0pA    4.0\n",
      "924441  -_2h2cJlBOWAYrfplMU-Cg  cFSyJluKa2SHtgMMvlx6SQ    5.0\n",
      "\n",
      "[887 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df[df['user_id'].isin(list(CC_max.nodes()))]\n",
    "N = df.drop_duplicates(subset = ['user_id'])\n",
    "print(N)\n",
    "M = df.drop_duplicates(subset = ['business_id'])\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Από το Ν που έχει τους χρήστες, ανακατεύουμε και παίρνουμε τους πρώτους 100 στην μεταβλητή test_users. Από το DataFrame df παίρνουμε όσες τριάδες περιέχουν user_id από το test_users</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = N.sample(frac=1)\n",
    "test_users = N.iloc[:100]\n",
    "union_bus = df[df.user_id.isin(test_users.user_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Βρίσκουμε τώρα ποιοι από τους χρήστες έχουν κάνει review στα ίδια εστιατόρια.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = union_bus.groupby('business_id')['user_id'].apply(set)\n",
    "filtered = grouped[grouped.apply(len) > 1]\n",
    "test_3 = union_bus[union_bus['business_id'].isin(filtered.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Τώρα έχουμε ένα DataFrame test_3 με τριάδες όπου στα εστιατόρια έχουν κάνει review καποιοι από τους 100 που επιλέχθηκαν. Ανακατεύουμε το DataFrame και από επιλέγουμε τα πρώτα 100. Τώρα από το DataFrame test_3 κρατάμε μόνο τις τριάδες που έχουν business_id μέσα από τα 100 που επιλέχθηκαν. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       user_id             business_id  stars\n",
      "1202    R3L9EHSSEtdO-Kcunmzutg  QWqKTWQ2OiDgo3dzNkpung    4.0\n",
      "3984    h9x6C4vKVkkS7TVTWflB4g  tzVLTQNUtiCAxUZmEuF0vQ    4.0\n",
      "5659    -QmEKJ_CzZnT9biZHddfZQ  tzVLTQNUtiCAxUZmEuF0vQ    4.0\n",
      "6101    Sg_BvnTHsbc1AABiJjaiPA  wUnLSg_GKfEIQ5CQQ770_g    4.0\n",
      "10270   vzNYQaFyBnIU_bBkJsUJQA  QWqKTWQ2OiDgo3dzNkpung    5.0\n",
      "...                        ...                     ...    ...\n",
      "962227  BJYnLAu8SkwfiDogbADBtA  qISf5ojuYbD9h71NumGUQA    3.0\n",
      "963146  BJYnLAu8SkwfiDogbADBtA  rgeuy1qbw6Z8B6CSVANHIA    4.0\n",
      "965917  tUW0AXg4C3H9TP5lyhoQuA  c6hhh1Kpr7iau8qMH74w2Q    5.0\n",
      "966514  RgDVC3ZUBqpEe6Y1kPhIpw  c6hhh1Kpr7iau8qMH74w2Q    5.0\n",
      "966706  QVNFi8ssjPtHY5I9M1vb8Q  jkGQQ4_LgJx3hwPtCFkzbQ    1.0\n",
      "\n",
      "[727 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "M = test_3.drop_duplicates(subset = ['business_id'])\n",
    "M = M.sample(frac=1)\n",
    "test_bus = M.iloc[:100]\n",
    "final_test = test_3[test_3.business_id.isin(test_bus.business_id)]\n",
    "print(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                       user_id             business_id  stars_x\n",
       "0      smOvOajNG0lS4Pq7d8g4JQ  RZtGWDLCAtuipwaZ-UfjmQ      4.0\n",
       "1      IQsF3Rc6IgCzjVV9DE8KXg  eFvzHawVJofxSnD7TgbZtg      5.0\n",
       "2      ZGjgfSvjQK886kiTzLwfLQ  EtKSTHV5Qx_Q7Aur9o4kQQ      5.0\n",
       "3      IKbjLnfBQtEyVzEu8CuOLg  VJEzpfLs_Jnzgqh5A_FVTg      4.0\n",
       "4      NUtIAX-ygn474tDg5nmesg  6LCZLGa09Qifn6rG7-DNrg      4.0\n",
       "...                       ...                     ...      ...\n",
       "97506  bJ5FtCtZX3ZZacz2_2PJjA  wMQkdK2aNMvq2xoojC98Mw      4.0\n",
       "97507  bJ5FtCtZX3ZZacz2_2PJjA  SOsjW1JARmtHUFtpFlp8rw      4.0\n",
       "97508  LHWtjTG7e1NzNPYUbUo-9w  rgeuy1qbw6Z8B6CSVANHIA      5.0\n",
       "97509  7ziWZULyiZv2TesYNMFf4g  qQO7ErS_RAN4Vs1uX0L55Q      4.0\n",
       "97510  MCzlzlOw7IGbRAKVjJBPtg  fcGexL5VH5G2Xw0tRj9uOQ      3.0\n",
       "\n",
       "[97511 rows x 3 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train = df.merge(final_test,on=['user_id','business_id'],how='left')\n",
    "final_train = final_train.drop('stars_y', axis=1)\n",
    "final_train.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Διαβάζουμε τα έτοιμα από την εκφώνηση αρχεία train_data και test_data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_data.csv')\n",
    "B_test = test_data.drop_duplicates(subset = ['business_id'])\n",
    "test_data = test_data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "train_data = train_data.drop('Unnamed: 0', axis=1)\n",
    "train_data = train_data[train_data.business_id.isin(B_test['business_id'].values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Δημιουργούμε μια συνάρτηση initialize που αρχικοποιεί το γράφημα μας. Σε κάθε κόμβο-χρήστη του βάζουμε και ένα κλειδί business_id που έχει για τιμή την βαθμολογία του χρήστη. Όπως λέει η εκφώνηση, όσοι κόμβοι-χρήστες περιέχονται στο train έχουν σταθερά τιμη r, ενώ όσοι κόμβοι-χρήστες περιέχονται στο test τους αρχικοποιούμε σε 0, μια τιμή που δεν μπορεί να υπάρξει ως βαθμολογία (1-5).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(CC_max):\n",
    "    for x in CC_max.nodes:\n",
    "        # x is the user_id\n",
    "        # get the reviews of user x\n",
    "        reviews = train_data[train_data.user_id == x].values\n",
    "        for u_b_r in reviews:\n",
    "            # u_b_r[0]: the user_id (the x)\n",
    "            # u_b_r[1]: the business_id\n",
    "            # u_b_r[2]: the rating\n",
    "            CC_max.nodes[x][u_b_r[1]] = u_b_r[2]\n",
    "    \n",
    "    for x in CC_max.nodes:\n",
    "        # x is the user_id\n",
    "        # get the reviews of user x\n",
    "        reviews = test_data[test_data.user_id == x].values\n",
    "        for u_b_r in reviews:\n",
    "            # u_b_r[0]: the user_id (the x)\n",
    "            # u_b_r[1]: the business_id\n",
    "            # u_b_r[2]: the rating\n",
    "            CC_max.nodes[x][u_b_r[1]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Εδώ υλοποιείται το value propagation. Ξεκινάμε και παίρνουμε έναν-έναν τους κόμβους του test και για κάθε κλειδί-business_id κοιτάμε τις βαθμολογίες από τους γείτονες του και παίρνουμε το μέσο όρο τους. Φυσικά, πρώτα όσοι κόμβοι είναι κοντά στους κόμβους του train θα γίνει σε αυτούς πρώτα η διάχυση τιμών. Μα με τα iteration, και εκείνοι οι κόμβοι του test που θα είναι \"πιο μακριά\" θα γίνει διάχυση τιμών και σε αυτούς. Τερματίζουμε όταν φτάσουμε τα max iterations ή όταν γίνει ένα ολόκληρο iteration χωρίς μεγάλη αλλαγή.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iters: 70\n",
      "Reached max iter\n"
     ]
    }
   ],
   "source": [
    "def value_propagation(CC_max, max_iter = 10):\n",
    "    all_users = test_data.drop_duplicates(subset = ['user_id'])\n",
    "    test_users = all_users['user_id'].values\n",
    "    print(\"Max iters:\",max_iter)\n",
    "    iter_counter = 0\n",
    "    user_counter = 0\n",
    "    error_counter = 0\n",
    "    review_counter = 0\n",
    "    initialize(CC_max)\n",
    "    while(True):\n",
    "        # get the node that holds the user (the user is from test_data)\n",
    "        user = CC_max.nodes[test_users[user_counter]]\n",
    "        # get the list of the business that he has reviewed\n",
    "        business_data = list(user.keys())\n",
    "        # get the neighbors of the user\n",
    "        neighbors = list(CC_max.neighbors(test_users[user_counter]))\n",
    "        for bus in business_data:\n",
    "            review_counter += 1\n",
    "            # get current value of the stars. We initialized it at 0. (let's call it old)\n",
    "            old_value = CC_max.nodes[test_users[user_counter]][bus]\n",
    "            \n",
    "            \n",
    "            # here we hold the stars of the neighbors\n",
    "            all_neighbor_stars = np.array([])\n",
    "            \n",
    "            # iterate through all friends, if they have reviewed the same business, append the stars\n",
    "            for friend in neighbors:\n",
    "                # here we hold the businesses of the neighbor\n",
    "                neighbor_reviews = list(CC_max.nodes[friend].keys())\n",
    "                if(bus in neighbor_reviews):\n",
    "                    if(CC_max.nodes[friend][bus] == 0):\n",
    "                        continue\n",
    "                    all_neighbor_stars = np.append(all_neighbor_stars, CC_max.nodes[friend][bus])\n",
    "            \n",
    "            # calculate R\n",
    "            if(len(all_neighbor_stars) != 0):\n",
    "                R = np.sum(all_neighbor_stars) / len(all_neighbor_stars)\n",
    "            else:\n",
    "                R = 0\n",
    "            \n",
    "            # change the value\n",
    "            CC_max.nodes[test_users[user_counter]][bus] = R\n",
    "            # initialize back to empty array\n",
    "            all_neighbor_stars = np.array([])\n",
    "            \n",
    "            if(not (old_value == 0 or R == 0)):\n",
    "                if((abs(old_value-R) > 1/100000000)):\n",
    "                    error_counter = 0\n",
    "            error_counter += 1\n",
    "                    \n",
    "            \n",
    "        # +1\n",
    "        user_counter += 1\n",
    "        \n",
    "        if(user_counter == 100):\n",
    "            error_counter = 0\n",
    "            iter_counter += 1\n",
    "            user_counter = 0\n",
    "            review_counter = 0\n",
    "        \n",
    "        if(iter_counter == max_iter):\n",
    "            print(\"Reached max iter\")\n",
    "            break\n",
    "value_propagation(CC_max,70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Μετά την διάχυση παίρνουμε όλα τα review στα εστιατόρια και δημιουργούμε ένα DataFrame με αυτές τις τριάδες, user_id business_id και stars. Μετά αφαιρούμε όσες τριάδες περιέχουν στην στήλη stars 0, πράγμα που σημαίνει ότι δεν έγινε διάχυση τιμής για αυτό το review.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                     user_id             business_id  stars_pred  stars\n",
       "0    FlXBpK_YZxLo27jcMdII1w  AlxnbBd2JNkozNvI0OvRLQ    5.000000    4.0\n",
       "1    FlXBpK_YZxLo27jcMdII1w  AlxnbBd2JNkozNvI0OvRLQ    5.000000    3.0\n",
       "2    FlXBpK_YZxLo27jcMdII1w  4_W5pstoN1166TGjjPOrMg    3.936042    4.0\n",
       "3    FlXBpK_YZxLo27jcMdII1w  muCelHtTlX5PrJd8JKkf_w    3.400000    4.0\n",
       "4    FlXBpK_YZxLo27jcMdII1w  AmI3LIUNwsi4023hOVGu3w    4.363636    2.0\n",
       "..                      ...                     ...         ...    ...\n",
       "792  Th-A3NlhCWBqbTzBZ9Tc2w  jkGQQ4_LgJx3hwPtCFkzbQ    3.000000    5.0\n",
       "793  -2cKJFFNJ9XVyWBt62mWvA  L0zMk5SXnqR0JLEe0XY20g    4.122658    5.0\n",
       "794  oNNL-ykTZx5S-xf66SOVjQ  _UOg5_pk9IhKee91eWrT4A    4.073849    5.0\n",
       "795  oNNL-ykTZx5S-xf66SOVjQ  xQE1fuwKCXJEBcJgSSCNbw    3.946429    5.0\n",
       "796  oNNL-ykTZx5S-xf66SOVjQ  dG-gZOWzn8iO1Rvv_fbXxA    3.802203    5.0\n",
       "\n",
       "[648 rows x 4 columns]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = []\n",
    "result = pd.DataFrame()\n",
    "test_users_list = test_data['user_id'].values\n",
    "for x in CC_max.nodes:\n",
    "        # x is the user_id\n",
    "        # get the data of user x\n",
    "        if(x not in test_users_list): continue\n",
    "        user_dict = CC_max.nodes[x]\n",
    "        local_df = pd.DataFrame(user_dict.items())\n",
    "        local_df.columns = ['business_id','stars_pred']\n",
    "        local_df['user_id'] = x\n",
    "        local_df = local_df.reindex(columns=['user_id','business_id','stars_pred'])\n",
    "        result = result.append(local_df)\n",
    "merged_df = result.merge(test_data, how = 'inner', on = ['user_id','business_id'])\n",
    "\n",
    "merged_df = merged_df[merged_df.stars_pred != 0]\n",
    "merged_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> To RMSE.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9414033539310246\n"
     ]
    }
   ],
   "source": [
    "merged_df['diff'] = merged_df['stars_pred'] - merged_df['stars']\n",
    "merged_df['diff_sqr'] = merged_df['diff'].apply(lambda x: x**2)\n",
    "sum_diff = merged_df.sum(axis=0)\n",
    "rmse = np.sqrt(sum_diff[5]/len(merged_df['diff'].values))\n",
    "print(\"RMSE:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Διαβάζουμε τα fixed train/test set από την εκφώνηση. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"train_data.csv\")\n",
    "test_set = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Εδώ δημιουργούμε τον πίνακα με τις μέσες τιμές των user_id. Κάνουμε group_by και μέσα σε κάθε υπό-DataFrame του user_id βρίσκουμε το μέσο όρο της στήλης stars. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_groups = train_set.groupby('user_id')\n",
    "user_scores_dic = {'user_id':[],'mean_star':[]}\n",
    "\n",
    "for user_id, user_data in user_groups:\n",
    "    user_scores_dic['user_id'].append(user_id)\n",
    "    user_scores_dic['mean_star'].append(user_data['stars'].mean())\n",
    "\n",
    "#user_scores = pd.DataFrame(user_scores_dic, columns = ['user_id','mean_star'])\n",
    "user_scores = pd.DataFrame.from_dict(user_scores_dic)\n",
    "user_scores.columns = ['user_id','mean_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>mean_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2cKJFFNJ9XVyWBt62mWvA</td>\n",
       "      <td>4.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9OIms4jE1bdD1fz7AzAFA</td>\n",
       "      <td>3.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-A7wqNBMClbU6Y8NNLdMvw</td>\n",
       "      <td>4.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-G7Zkl1wIWBBmD0KRy_sCw</td>\n",
       "      <td>3.898551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-HYCAMf2ml717YD5Y9PKIg</td>\n",
       "      <td>3.617647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  mean_star\n",
       "0  -2cKJFFNJ9XVyWBt62mWvA   4.405405\n",
       "1  -9OIms4jE1bdD1fz7AzAFA   3.967742\n",
       "2  -A7wqNBMClbU6Y8NNLdMvw   4.096774\n",
       "3  -G7Zkl1wIWBBmD0KRy_sCw   3.898551\n",
       "4  -HYCAMf2ml717YD5Y9PKIg   3.617647"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Εδω υλοποιείται ο User Average (UA) αλγόριθμος. Για αρχή κάνουμε group_by σύμφωνα με τους users και διατρέχουμε τα dataframes του κάθε user. Με την χρήση του .loc και του user_id (από το iteration) βρίσκουμε στο datafrane user_scores την μέση τιμή του κάθε user και αφαιρούμε αυτήν την τιμή από όλες τια βαθμολογίες που έχει κάνει ο user στην στήλη 'stars'. Τετραγωνίζουμε την διαφορά και κρατάμε σε δύο παραμέτρους το άθροισμα τους και το πλήθος των χρηστών, πλήθος το όποιο ξέρουμε ήδη ούτως ή άλλως. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_groups_test = test_set.groupby('user_id')\n",
    "error_sum = 0\n",
    "count = 0\n",
    "\n",
    "for user_id, user_data in user_groups_test:\n",
    "    error_column_diff = user_data[\"stars\"]-user_scores.loc[user_scores[\"user_id\"] == user_id]['mean_star'].values[0]\n",
    "    error_column_sqr = error_column_diff**2\n",
    "    error_sum += error_column_sqr.sum()\n",
    "    count += len(error_column_sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of User Average: 0.9012981678615513\n",
      "Time: 0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmse = np.sqrt(error_sum/count)\n",
    "print(\"RMSE of User Average:\",rmse)\n",
    "end = time.time()\n",
    "print(\"Time:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Εδώ δημιουργούμε τον πίνακα με τις μέσες τιμές των business_id. Κάνουμε group_by και μέσα σε κάθε υπό-DataFrame του business_id βρίσκουμε το μέσο όρο της στήλης stars. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_groups = train_set.groupby('business_id')\n",
    "bus_scores_dic = {'business_id':[],'mean_star':[]}\n",
    "\n",
    "for business_id, bus_data in bus_groups:\n",
    "    bus_scores_dic['business_id'].append(business_id)\n",
    "    bus_scores_dic['mean_star'].append(bus_data['stars'].mean())\n",
    "\n",
    "bus_scores = pd.DataFrame.from_dict(bus_scores_dic)\n",
    "bus_scores.columns = ['business_id','mean_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>mean_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0TffRSXXIlBYVbb5AwfTg</td>\n",
       "      <td>4.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1B9pP_CrRBJYPICE5WbRA</td>\n",
       "      <td>3.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4HMjEGQgduIMMTe0WPQBA</td>\n",
       "      <td>3.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5Rah4ZvWsDu4oilUZxhtw</td>\n",
       "      <td>3.938596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-ATiAtTikuGuqvaW2O6tNA</td>\n",
       "      <td>3.471014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  mean_star\n",
       "0  -0TffRSXXIlBYVbb5AwfTg   4.244000\n",
       "1  -1B9pP_CrRBJYPICE5WbRA   3.761589\n",
       "2  -4HMjEGQgduIMMTe0WPQBA   3.652174\n",
       "3  -5Rah4ZvWsDu4oilUZxhtw   3.938596\n",
       "4  -ATiAtTikuGuqvaW2O6tNA   3.471014"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black; font-weight:700;font-size:18px\"> Εδω υλοποιείται ο Business Average (BA) αλγόριθμος. Όπως πριν, για αρχή κάνουμε group_by σύμφωνα με τα business και διατρέχουμε τα dataframes του κάθε business. Με την χρήση του .loc και του business_id (από το iteration) βρίσκουμε στο datafrane bus_scores την μέση τιμή του κάθε business και αφαιρούμε αυτήν την τιμή από όλες τις βαθμολογίες που έχουν κάνει στην επιχείρηση στην στήλη 'stars'. Τετραγωνίζουμε την διαφορά και κρατάμε σε δύο παραμέτρους το άθροισμα τους και το πλήθος των επιχειρήσεων, πλήθος το όποιο ξέρουμε ήδη ούτως ή άλλως. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_groups_test = test_set.groupby('business_id')\n",
    "error_sum = 0\n",
    "count = 0\n",
    "\n",
    "for business_id, business_data in bus_groups_test:\n",
    "    error_column_diff = business_data[\"stars\"]-bus_scores.loc[bus_scores[\"business_id\"] == business_id]['mean_star'].values[0]\n",
    "    error_column_sqr = error_column_diff**2\n",
    "    error_sum += error_column_sqr.sum()\n",
    "    count += len(error_column_sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8698495174282991\n",
      "Time: 0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmse = np.sqrt(error_sum/count)\n",
    "print(rmse)\n",
    "end = time.time()\n",
    "print(\"Time:\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
